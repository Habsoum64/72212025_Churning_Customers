# -*- coding: utf-8 -*-
"""Assignment_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DnHdLTSmoP7_6E-NVsKeKhSg8UUof_Hq
"""

import numpy as np
import pandas as pd
from google.colab import drive
drive.mount('/content/drive')

# Loading the dataset
df = pd.read_csv('/content/drive/My Drive/Intro to AI/Assignment_3/CustomerChurn_dataset.csv')
df.drop('customerID', axis=1, inplace=True)
df.info()

# Number of null values in the dataset
df.isna().sum()

# ** Converting TotalCharges to Float
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce').fillna(np.mean)
df.info()

df.isna().sum()

# Libraries for graphing & EDA
import seaborn as sns
import matplotlib.pyplot as plt

# Splitting the dataset based on churning
churned = df.loc[lambda x: x['Churn'] == 'Yes']
stayed = df.loc[lambda x: x['Churn'] == 'No']

print("Number of Churns: " + str(len(churned.index)))
print("Number of Stays: " + str(len(stayed.index)))

fig0 = plt.figure(figsize = (15,10))

ax1 = fig0.add_subplot(2,3,1)
sns.countplot(data = churned, x = 'gender', ax=ax1)

ax2 = fig0.add_subplot(2,3,2)
sns.countplot(data = stayed, x = 'gender', ax=ax2)

fig1 = plt.figure(figsize = (15,10))

ax1 = fig1.add_subplot(2,3,1)
sns.countplot(data = churned, x = 'SeniorCitizen', ax=ax1)

ax2 = fig1.add_subplot(2,3,2)
sns.countplot(data = churned, x = 'Partner', ax=ax2)

ax3 = fig1.add_subplot(2,3,3)
sns.countplot(data = churned, x = 'Dependents', ax=ax3)

ax4 = fig1.add_subplot(2,3,4)
sns.countplot(data = churned, x = 'PhoneService', ax=ax4)

fig2 = plt.figure(figsize = (15,10))

ax1 = fig2.add_subplot(2,3,1)
sns.countplot(data = churned, x = 'MultipleLines', ax=ax1)

ax2 = fig2.add_subplot(2,3,2)
sns.countplot(data = churned, x = 'InternetService', ax=ax2)

ax3 = fig2.add_subplot(2,3,3)
sns.countplot(data = churned, x = 'OnlineSecurity', ax=ax3)

ax4 = fig2.add_subplot(2,3,4)
sns.countplot(data = churned, x = 'OnlineBackup', ax=ax4)

ax5 = fig2.add_subplot(2,3,5)
sns.countplot(data = churned, x = 'DeviceProtection', ax=ax5)

ax6 = fig2.add_subplot(2,3,6)
sns.countplot(data = churned, x = 'TechSupport', ax=ax6)

fig3 = plt.figure(figsize = (15,10))

ax1 = fig3.add_subplot(2,3,1)
sns.countplot(data = churned, x = 'StreamingTV', ax=ax1)

ax2 = fig3.add_subplot(2,3,2)
sns.countplot(data = churned, x = 'StreamingMovies', ax=ax2)

ax3 = fig3.add_subplot(2,3,3)
sns.countplot(data = churned, x = 'Contract', ax=ax3)

ax4 = fig3.add_subplot(2,3,4)
sns.countplot(data = churned, x = 'PaperlessBilling', ax=ax4)

fig4 = plt.figure(figsize = (10,10))
sns.countplot(data = churned, x = 'PaymentMethod')

churned.hist(bins=50, figsize=(15,10))
plt.show()

# ** Isolating numerical & categorical data
numerical = df.select_dtypes(exclude=['object'])
categorical = df.select_dtypes(include=['object'])

# ** Factorizing categorical values (turning them into numbers)
cat_columns = list(categorical.columns.values)
for col in cat_columns:
  categorical[col], b = pd.factorize(categorical[col])

data = pd.concat([categorical, numerical], axis=1)
data

data.info()

X = data.drop('Churn', axis=1)
y = data['Churn']

corr_matrix = X.corrwith(y)
corr_matrix.sort_values(ascending=False)

high_corr = corr_matrix[abs(corr_matrix)>0.25].index.tolist()
high_corr

from sklearn.feature_selection import mutual_info_regression
mutual_info_scores = mutual_info_regression(X, y)

# Select the features that have a mutual information score greater than 0.5
relevant_features = []
print("_______ Mutual information Scores for each features _______")

for i in range(len(mutual_info_scores)):
  feature = X.columns.values[i]
  score = mutual_info_scores[i]
  print(feature + ": " + str(score))

  if round(score, 2) >= 0.05:
        relevant_features.append(feature)

print("\nRelevant features:")
print(relevant_features)

from sklearn.feature_selection import SelectKBest

# Create a SelectKBest selector to select the top 10 features based on information gain
selector = SelectKBest(k=10)

# Fit the selector to the data
selector.fit(data.drop('Churn', axis=1), data['Churn'])

# Extract the relevant features from the dataset
relevant_features = []
print("_______ SelectKBest Scores for each features _______")

for i in range(len(selector.scores_)):
  feature = X.columns.values[i]
  score = selector.scores_[i]
  print("- " + feature + ": " + str(score))


relevant_features = selector.get_feature_names_out()
print("\nRelevant features:")
print(relevant_features)

from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier

clf = RandomForestClassifier()
selector = RFE(estimator=clf, n_features_to_select=10)
selector.fit(X, y)

selector.get_feature_names_out()

from sklearn.ensemble import RandomForestClassifier
# Feature importance using RandomForest Classfier

clf.fit(X, y)
feature_importances = clf.feature_importances_

# Selecting the features that have the highest feature importance scores
relevant_features = []
for i in range(len(feature_importances)):
    if feature_importances[i] > np.mean(feature_importances):
        relevant_features.append(X.columns[i])

relevant_features

from sklearn.model_selection import GridSearchCV
from sklearn.feature_selection import SelectFromModel

clf = RandomForestClassifier(random_state=42)

# Parameter grid for GridSearchCV
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X.copy(), y)

# Getting the best parameters and the corresponding model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

# Transforming the data to keep only important features
sfm = SelectFromModel(best_model, threshold=0.1)
sfm.fit(X.copy(), y)
X_selected = sfm.transform(X.copy())

# Selected features
selected_feature_indices = np.where(sfm.get_support())[0]
selected_feature_names = X.columns[selected_feature_indices]

print("Selected Features:", selected_feature_names)

training_features = [
                     'PhoneService','OnlineSecurity', 'TechSupport',
                     'DeviceProtection', 'Contract', 'PaymentMethod',
                     'tenure', 'MonthlyCharges', 'TotalCharges'
                     ]

X = data[training_features]
X

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from tensorflow.keras import layers, models
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

def model():
  input_layer = Input(shape=(X_scaled.shape[1],))
  hidden_layer_1 = Dense(128, activation='elu')(input_layer)
  hidden_layer_2 = Dense(64, activation='relu')(hidden_layer_1)
  dropout_layer_1 = Dropout(0.25)(hidden_layer_1)
  hidden_layer_3 = Dense(56, activation='relu')(hidden_layer_2)
  dropout_layer_4 = Dropout(0.25)(hidden_layer_3)
  hidden_layer_4 = Dense(16, activation='tanh')(dropout_layer_4)
  hidden_layer_5 = Dense(16, activation='relu')(hidden_layer_4)
  output_layer = Dense(1, activation='sigmoid')(hidden_layer_5)

  model = Model(inputs=input_layer, outputs=output_layer)
  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

  return model

!pip install scikeras

from scikeras.wrappers import KerasClassifier
keras_classifier = KerasClassifier(build_fn=model, epochs=50, batch_size=8)

from sklearn.model_selection import GridSearchCV
param_grid = {
    'epochs':[10, 20, 30, 40],
    'batch_size': [16, 32, 64, 128],
}

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=keras_classifier, param_grid=param_grid, scoring='accuracy', cv=5, verbose=1)

grid_search.fit(X_train, y_train)

print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Accuracy: {grid_search.best_score_}")

from sklearn.metrics import roc_auc_score
best_model = grid_search.best_estimator_

y_pred_prob = best_model.predict_proba(X_test)

auc_score = roc_auc_score(y_test, y_pred_prob[:, 1])
print(f'AUC score: {auc_score}' )

test_loss, test_acc = best_model.model_.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

# Split the training set further into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

model = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))

test_loss, test_acc = model.model_.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

y_pred_prob = model.predict_proba(X_test)

auc_score = roc_auc_score(y_test, y_pred_prob[:, 1])
print(f'AUC score: {auc_score}' )

model.model_.save("churn.h5")